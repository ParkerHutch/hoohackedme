{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14344391\n"
     ]
    }
   ],
   "source": [
    "lines = []\n",
    "# need errors='ignore' to get rid of some utf-8 errors when decoding\n",
    "with open('rockyou.txt', 'r', encoding='utf-8', errors='ignore') as data_file:\n",
    "    for line in data_file:\n",
    "        lines.append(line.rstrip())\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(X_train)=10041074 (70.0%), len(X_test)=2868878 (20.0%), len(X_val)=1434439 (10.0%)\n"
     ]
    }
   ],
   "source": [
    "test_proportion = 0.2\n",
    "validation_proportion = 0.1\n",
    "test_set_count = (int) (test_proportion * len(lines))\n",
    "validation_set_count = (int) (validation_proportion * len(lines))\n",
    "\n",
    "\n",
    "X_train, X_test = train_test_split(lines, test_size=test_set_count, random_state=1)\n",
    "X_train, X_val = train_test_split(X_train, test_size=validation_set_count, random_state=1)\n",
    "\n",
    "print(f'{len(X_train)=} ({round(len(X_train) / len(lines), 2) * 100}%), {len(X_test)=} ({round(len(X_test) / len(lines), 2) * 100}%), {len(X_val)=} ({round(len(X_val) / len(lines), 2) * 100}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Chain Model\n",
    "\n",
    "Borrowed from [here](https://github.com/brannondorsey/markov-passwords/tree/master)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# X_train = lines\n",
    "stats = {}\n",
    "max_ngrams = 3\n",
    "for idx, line in enumerate(X_train):\n",
    "\tX_train[idx] += '\\n' # to make the next part work\n",
    "\n",
    "# create a list of ngrams from a single line in\n",
    "# the training data\n",
    "def get_ngram(line, n):\n",
    "\toutput = []\n",
    "\tfor i, char in enumerate(line):\n",
    "\t\t# use backticks as start of line characters\n",
    "\t\t# e.g. test == \"```t... ``te... `tes... test\" for 4grams\n",
    "\t\tif i - n < 0:\n",
    "\t\t\tbuff = ''\n",
    "\t\t\tfor j in range(abs(i - n)):\n",
    "\t\t\t\tbuff += '`'\n",
    "\t\t\tbuff += line[0:i]\n",
    "\t\t\toutput.append((buff, char))\n",
    "\t\telse:\n",
    "\t\t\toutput.append((line[i - n:i], char))\n",
    "\treturn output\n",
    "\n",
    "for line in X_train:\n",
    "    # add ngrams to the stats dict for all n less than or\n",
    "    # equal to max_ngrams (unigrams, bigrams, trigrams, etc...)\n",
    "\t# line = line + '\\\\n'\n",
    "\tfor i in range(max_ngrams):\n",
    "\t\tfor gram in get_ngram(line, i + 1):\n",
    "\t\t\tprev = gram[0] # previous characters, ngram\n",
    "\t\t\tnxt = gram[1] # next character\n",
    "\t\t\t# if this ngram hasn't been seen yet\n",
    "\t\t\t# add it to the stats dict\n",
    "\t\t\tif not prev in stats:\n",
    "\t\t\t\tstats[prev] = {}\n",
    "\t\t\t# if the next character hasn't been seen to\n",
    "\t\t\t# follow the ngram yet, add it the ngram's \n",
    "\t\t\t# dict of seen characters\n",
    "\t\t\tif not nxt in stats[prev]:\n",
    "\t\t\t\tstats[prev][nxt] = 0\n",
    "\t\t\t# increment the statistic\n",
    "\t\t\tstats[prev][nxt] += 1\n",
    "\n",
    "# convert frequency counts to probabilities\n",
    "for ngram in stats:\n",
    "\t\n",
    "\tchars = []\n",
    "\toccur = []\n",
    "\tprobs = []\n",
    "\n",
    "\tfor key, value in stats[ngram].items():\n",
    "\t\tchars.append(key)\n",
    "\t\toccur.append(value)\n",
    "\n",
    "\ttotal = sum(occur)\n",
    "\tprobs = [float(x) / float(total) for x in occur]\n",
    "\n",
    "\tfor key, value in stats[ngram].items():\n",
    "\t\tstats[ngram][key] = float(value) / float(total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "melody2005\n",
      "\n",
      "[('````', 'm'), ('```m', 'e'), ('``me', 'l'), ('`mel', 'o'), ('melo', 'd'), ('elod', 'y'), ('lody', '2'), ('ody2', '0'), ('dy20', '0'), ('y200', '5'), ('2005', '\\n')]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])\n",
    "print(get_ngram(X_train[0], 4))\n",
    "# print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hubberstanson4\n",
      "GsmHjW5\n",
      "sanijeff080\n",
      "kozmine\n",
      "gie8\n",
      "amthewr\n",
      "xuelle\n",
      "1253\n",
      "eb7r2bewe\n",
      "hij7774r1chien\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "max_ngrams = 3 # ngram size\n",
    "num_generate = 10 # number of passwords to generate\n",
    "\n",
    "# generate a single new password using a stats dict\n",
    "# created during the training phase \n",
    "def gen_password(n):\n",
    "\toutput = '`' * n\n",
    "\tfor i in range(100):\n",
    "\t\toutput += gen_char(output[i:i + n])\n",
    "\t\tif output[-1] == '\\n':\n",
    "\t\t\treturn output[0:-1].replace('`', '')[0:-1]\n",
    "\n",
    "# Sample a character if the ngram appears in the stats dict.\n",
    "# Otherwise recursively decrement n to try smaller grams in\n",
    "# hopes to find a match (e.g. \"off\" becomes \"of\").\n",
    "# This is a deviation from a vanilla markov text generator\n",
    "# which one n-size. This generator uses all values <= n.\n",
    "# preferencing higher values of n first. \n",
    "import random\n",
    "def gen_char(ngram):\n",
    "\tif ngram in stats:\n",
    "\t\t# sample from the probability distribution\n",
    "\t\treturn random.choices(list(stats[ngram].keys()), weights=stats[ngram].values(), k=1)[0]\n",
    "\t\t# return np.random.choice(stats[ngram].keys(), p=stats[ngram].values())\n",
    "\telse:\n",
    "\t\t# print('{} not in stats dict'.format(ngram))\n",
    "\t\treturn gen_char(ngram[0:-1])\n",
    "\n",
    "# with open('data/{}-gram.pickle'.format(max_ngrams)) as file:\n",
    "# \tstats = pickle.load(file)\n",
    "\n",
    "# start = time.time()\n",
    "\n",
    "for i in range(num_generate):\n",
    "\tpw = gen_password(max_ngrams)\n",
    "\tif pw is not None:\n",
    "\t\tprint(pw)\n",
    "\n",
    "# print('finished in {:.2f} seconds'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Password Proposal Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will try to get the markov chain model to estimate the probability that a password appears in RockYou based on its transition weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.005967640109821e-10\n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "example_password = gen_password(1)\n",
    "# print(example_password)\n",
    "# print(list(stats['h']))\n",
    "# stats[ngram][key] = float(value) / float(total)\n",
    "probability = stats['`'][example_password[0]]\n",
    "for idx, first_letter in enumerate(example_password):\n",
    "    next_letter_idx = idx + 1\n",
    "    if next_letter_idx < len(example_password):\n",
    "        probability *= stats[first_letter][example_password[next_letter_idx]]\n",
    "\n",
    "print(probability)\n",
    "# print(stats['h']['u'])\n",
    "# print(list(stats.keys())[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}